# -*- coding: utf-8 -*-
"""face_identification_2fighters.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_SXrZJGqWl_FxO4N-bWUTPTFlCvZpGWy
"""

pip install mtcnn

pip install nptyping

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
from tensorflow import keras
from keras.models import load_model
import mtcnn
from os import listdir
from os.path import isdir
from PIL import Image
from matplotlib import pyplot
from numpy import savez_compressed
from numpy import asarray
from numpy import load
from numpy import expand_dims
from mtcnn.mtcnn import MTCNN
from nptyping import UInt8
from nptyping import NDArray
from nptyping import Unicode
from typing import Tuple
from typing import List
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import Normalizer
from sklearn.svm import SVC
from random import choice
import matplotlib.pyplot as plt
import numpy as np
import os

from google.colab import drive
drive.mount('/content/drive')

TRAIN_SET_PATH = '/content/drive/My Drive/UFC-model-tutorial-branch/ufc-project/2-ufc-fighters/train'
TESTE_SET_PATH = '/content/drive/My Drive/UFC-model-tutorial-branch/ufc-project/2-ufc-fighters/test'
PATH_TO_LOAD_FACENET_MODEL = '/content/drive/My Drive/UFC-model-tutorial-branch/ufc-project/FaceNet/model/facenet_keras.h5'
FACES_PATH = '/content/drive/My Drive/UFC-model-tutorial-branch/ufc-project/2-ufc-fighters/'

model = load_model(PATH_TO_LOAD_FACENET_MODEL, compile = False)

def extract_image_from_path(filename: str) -> np.ndarray:
	
  #file = os.path.join(global_image_path, filename)
  image = Image.open(filename).convert('RGB')
  pixels = np.asarray(image)
  
  return pixels


def extract_face_from_image_array(image_array: np.ndarray) -> np.ndarray:
  faces = detector.detect_faces(image_array)
  x1, y1, width, height = faces[0]['box']
  x1, y1 = abs(x1), abs(y1)
  x2, y2 = x1 + width, y1 + height
  face = image_array[y1:y2, x1:x2]
  
  return face

def resize_extracted_face(image_array: np.ndarray, required_size: Tuple[int, int] = (160, 160)) -> np.ndarray:
    image = Image.fromarray(image_array).resize(required_size)
    face_array = asarray(image)
  
    return face_array

def extract_face(filename: str, required_size: Tuple[int, int] = (160, 160)) -> np.ndarray:
  image = extract_image_from_path(filename)
  face = extract_face_from_image_array(image)
  resized_face = resize_extracted_face(face)

  return resized_face

def load_faces(directory: str) -> List[NDArray[(160, 160, 3), UInt8]]:
  """ Load images and extract faces for all images in a directory """

  faces = list()

  # enumerate files
  for filename in listdir(directory):
    # path
    path = directory + '/' + filename

    # get face
    face = extract_face(path)

    # store
    faces.append(face)

  return faces

def load_dataset(directory: str) \
      -> (List[NDArray[(92, 160, 160, 3), UInt8]], NDArray[(92,), Unicode[14]]):
  """ Load a dataset that contains one subdir for each class that in turn contains images """
	
  X, y = list(), list()
	
  # enumerate folders, on per class
  for subdir in listdir(directory):
    # path
    path = directory + '/' + subdir + '/'

    # skip any files that might be in the dir
    if not isdir(path):
      continue

    # load all faces in the subdirectory
    faces = load_faces(path)

    # create labels
    labels = [subdir for _ in range(len(faces))]

    # store
    X.extend(faces)
    y.extend(labels)
	
  return asarray(X), asarray(y)

detector = MTCNN()

# load train dataset
trainX, trainy = load_dataset(TRAIN_SET_PATH)

# load test dataset
testX, testy = load_dataset(TESTE_SET_PATH)

# save arrays to one file in compressed format
savez_compressed(FACES_PATH + '2-ufc-fighters-faces-dataset.npz', 
                 trainX, trainy, testX, testy)

def get_embedding(model, face_pixels):
  """ Get the face embedding for one face """

  # scale pixel values
  face_pixels = face_pixels.astype('float32')

  # standardize pixel values across channels (global)
  mean, std = face_pixels.mean(), face_pixels.std()
  face_pixels = (face_pixels - mean) / std

  # transform face into one sample
  samples = expand_dims(face_pixels, axis=0)

  # make prediction to get embedding
  yhat = model.predict(samples)

  return yhat[0]

# load the face dataset
data = load(FACES_PATH + '2-ufc-fighters-faces-dataset.npz')
trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']

# convert each face in the train set to an embedding
newTrainX = list()
for face_pixels in trainX:
	embedding = get_embedding(model, face_pixels)
	newTrainX.append(embedding)
newTrainX = asarray(newTrainX)

# convert each face in the test set to an embedding
newTestX = list()
for face_pixels in testX:
	embedding = get_embedding(model, face_pixels)
	newTestX.append(embedding)
newTestX = asarray(newTestX)

# save arrays to one file in compressed format
savez_compressed(FACES_PATH + '2-ufc-fighters-faces-embeddings.npz', 
                 newTrainX, trainy, newTestX, testy)

# load dataset
data = load(FACES_PATH + '2-ufc-fighters-faces-embeddings.npz')
trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']

# normalize input vectors
in_encoder = Normalizer(norm = 'l2')
trainX = in_encoder.transform(trainX)
testX = in_encoder.transform(testX)

# label encode targets
out_encoder = LabelEncoder()
out_encoder.fit(trainy)
trainy = out_encoder.transform(trainy)
testy = out_encoder.transform(testy)

# fit model
model = SVC(kernel = 'linear', probability = True)
model.fit(trainX, trainy)

# predict
yhat_train = model.predict(trainX)
yhat_test = model.predict(testX)

# score
score_train = accuracy_score(trainy, yhat_train)
score_test = accuracy_score(testy, yhat_test)

# load faces
data = load(FACES_PATH + '2-ufc-fighters-faces-dataset.npz')
testX_faces = data['arr_2']

# load face embeddings
data = load(FACES_PATH + '2-ufc-fighters-faces-embeddings.npz')
trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']

# normalize input vectors
in_encoder = Normalizer(norm = 'l2')
trainX = in_encoder.transform(trainX)
testX = in_encoder.transform(testX)

# label encode targets
out_encoder = LabelEncoder()
out_encoder.fit(trainy)
trainy = out_encoder.transform(trainy)
testy = out_encoder.transform(testy)

# fit model
model = SVC(kernel = 'linear', probability = True)
model.fit(trainX, trainy)

# test model on a random example from the test dataset
selection = choice([i for i in range(testX.shape[0])])
random_face_pixels = testX_faces[selection]
random_face_emb = testX[selection]
random_face_class = testy[selection]
random_face_name = out_encoder.inverse_transform([random_face_class])

# prediction for the face
samples = expand_dims(random_face_emb, axis = 0)
yhat_class = model.predict(samples)
yhat_prob = model.predict_proba(samples)

# get name
class_index = yhat_class[0]
class_probability = yhat_prob[0,class_index] * 100
predict_names = out_encoder.inverse_transform(yhat_class)

# plot for fun
plt.imshow(random_face_pixels)
plt.title("Expected: {0} \n Predicted: {1} {2:.3f}".format(random_face_name[0], predict_names[0], class_probability))
plt.show()

